{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from Functions_ReadBedFiles.ipynb\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import nbimporter\n",
    "from collections import Counter\n",
    "import functions_readbedfiles, functions_plot\n",
    "from functions_plot import create_data_traintest, create_data4T_SNE\n",
    "from Functions_ReadBedFiles import readJsonFile, readFiles2Vector, writeJsonFile, convertMat2document, readJsonFile\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import gc\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.font_manager as font_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from representations_regionset2vec.ipynb\n"
     ]
    }
   ],
   "source": [
    "from representations_regionset2vec import document_embedding_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization(clas_type, label, path_train, path_test, path_universe, path_mat, meta_data, sample_of_interest, path_w2v_model):\n",
    "    path_train = path_train.format(clas_type)\n",
    "    path_test = path_test.format(clas_type)\n",
    "    path_universe = path_universe.format(clas_type)\n",
    "    path_mat = path_mat\n",
    "    meta_data = pd.read_csv(meta_data.format(clas_type))\n",
    "    meta_data = meta_data.loc[meta_data[label].isin(sample_of_interest)][['Experiment_ID', label]]\n",
    "    model = Word2Vec.load(path_w2v_model.format(clas_type))\n",
    "    \n",
    "    return path_train, path_test, path_universe, path_mat, meta_data, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas_types = ['antibody', 'cell', 'tissue']\n",
    "labels = ['antibody', 'cell line', 'tissue']\n",
    "sample_of_interest = [['h3k27ac', 'h3k4me3', 'h3k27me3', 'h3k4me1', 'h3k36me3', 'h3k9me3', 'h3k4me2'],\n",
    "                     ['k562', 'mcf7', 'hek293', 'a549', 'hepg2', 'hct116','lovo', 'gm12878', 'lncap','hela'],\n",
    "                     ['liver', 'peripheral blood', 'primary prostate cancer', 'blood', 'breast','bone marrow', 'kidney']\n",
    "                     ]\n",
    "PCA_flg = False\n",
    "label = labels[i]\n",
    "clas_type = clas_types[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns = ['dataset','representation',  'pca', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = '/project/shefflab/www/papers/region_embedding/{}dataset/train/*'\n",
    "path_test = '/project/shefflab/www/papers/region_embedding/{}dataset/test/*'\n",
    "path_universe = './representations/{}/'\n",
    "path_mat = '/project/shefflab/data/ChIP-Atlas/term_doc_mat/'\n",
    "meta_data = './meta_data/meta_data_{}.csv'\n",
    "path_w2v_model = './word2vecmodels/word2vec_{}.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train, path_test, path_universe, path_mat, meta_data, model = initialization(clas_type, label, path_train, path_test, path_universe, path_mat, meta_data, sample_of_interest[i], path_w2v_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./representations/cell/cell_feature_1.0_atlas.bed\n",
      "Reading universe file: Done 2020-10-20 02:27:16.718419\n",
      "Reading bed files: Done 2020-10-20 02:27:16.739138\n",
      "Converting to matrix: Done 2020-10-20 02:27:16.739616\n",
      "0\n",
      "Reading universe file: Done 2020-10-20 02:27:16.767369\n",
      "Reading bed files: Done 2020-10-20 02:27:16.787188\n",
      "Converting to matrix: Done 2020-10-20 02:27:16.787636\n",
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'create_data4T_SNE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_data4T_SNE' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for path_univ in sorted(glob.glob(path_universe + \"*\")):\n",
    "    gc.collect()\n",
    "    pca = PCA(n_components= 100)\n",
    "    print(path_univ)\n",
    "    train_files , segmentation_df_train = readFiles2Vector(path_train, path_univ, numberofCores = 4, numOfFiles= 100, PATH = path_train)\n",
    "    print(len(train_files))\n",
    "    \n",
    "#     segmentation_df_train = None\n",
    "    \n",
    "    test_files, segmentation_df_test = readFiles2Vector(path_test, path_univ, numberofCores = 4, numOfFiles= 100, PATH = path_test)\n",
    "    print(len(test_files))\n",
    "    \n",
    "#     segmentation_df_test = None\n",
    "\n",
    "    X_train, y_train = create_data4T_SNE(train_files, (meta_data.loc[(meta_data[label] !='none') & (meta_data[label] !='nan') & (meta_data[label].notna())]), label, 0, 'Experiment_ID')\n",
    "    print(len(X_train), len(y_train))\n",
    "    X_test, y_test = create_data4T_SNE(test_files, (meta_data.loc[(meta_data[label] !='none') & (meta_data[label] !='nan') & (meta_data[label].notna())]), label, 0, 'Experiment_ID')\n",
    "    print(len(X_test), len(y_test))\n",
    "    print('Done')\n",
    "    \n",
    "    if(PCA_flg == True):\n",
    "        X_train = pca.fit_transform(X_train)\n",
    "        X_test = pca.transform(X_test)\n",
    "#     print(len(X_train[0]), len(X_test[0]))\n",
    "    \n",
    "#     clf = RandomForestClassifier(max_depth= 10, random_state=10)\n",
    "    clf = svm.SVC(kernel = 'linear')\n",
    "    start_time = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    f1 = f1_score((y_test), clf.predict(X_test), average = 'micro')\n",
    "    print(f1_score((y_test), clf.predict(X_test), average = 'micro'))\n",
    "    results = pd.concat([results, pd.DataFrame([[clas_type, path_univ.split('/')[-1], PCA_flg, f1]], columns= ['dataset','representation',  'pca', 'f1'])], ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "document_json_train = '/project/shefflab/data/ChIP-Atlas/term_doc_mat/document_{}_universe-txt_train.json'.format(clas_type)\n",
    "with open(document_json_train, 'r') as j:\n",
    "    document_Embedding_train =  json.loads(j.read())\n",
    "    \n",
    "document_json_test = '/project/shefflab/data/ChIP-Atlas/term_doc_mat/document_{}_universe-txt_test.json'.format(clas_type)\n",
    "with open(document_json_test, 'r') as j:\n",
    "    document_Embedding_test =  json.loads(j.read())\n",
    "    \n",
    "\n",
    "document_Embedding_avg_train = document_embedding_avg(document_Embedding_train, model)\n",
    "document_Embedding_avg_test = document_embedding_avg(document_Embedding_test, model)\n",
    "    \n",
    "X_train, y_train = create_data4T_SNE(document_Embedding_avg_train, (meta_data.loc[(meta_data[label] !='none') & (meta_data[label] !='nan') & (meta_data[label].notna())]), label, 0, 'Experiment_ID')\n",
    "X_test, y_test = create_data4T_SNE(document_Embedding_avg_test, (meta_data.loc[(meta_data[label] !='none') & (meta_data[label] !='nan') & (meta_data[label].notna())]), label, 0, 'Experiment_ID')\n",
    "\n",
    "print(len(X_train), len(y_train))\n",
    "print(len(X_test), len(y_test))\n",
    "\n",
    "# clf = RandomForestClassifier(max_depth= 10, random_state=10)\n",
    "clf = svm.SVC(kernel = 'linear')\n",
    "start_time = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "f1 = f1_score((y_test), clf.predict(X_test), average = 'micro')\n",
    "print(f1_score((y_test), clf.predict(X_test), average = 'micro'))\n",
    "results = pd.concat([results, pd.DataFrame([[clas_type, 'Region-set2vec', PCA_flg, f1]], columns= ['dataset', 'representation',  'pca', 'f1'])], ignore_index=True)\n",
    "\n",
    "results.to_csv('./Results/F1_class{}_pca{}.csv'.format(clas_type, PCA_flg), index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
